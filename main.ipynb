{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0915415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from rembg import remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0de425",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rename_files(folder_path):\n",
    "    # Ensure the provided path is a directory\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(\"Error: Not a valid directory.\")\n",
    "        return\n",
    "\n",
    "    # Get a list of files in the directory\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Sort the files to ensure a consistent order\n",
    "    files.sort()\n",
    "\n",
    "    # Rename each file with a numbered prefix\n",
    "    for i, file_name in enumerate(files):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Generate a new name with a numerical prefix\n",
    "        new_name = f\"{i+1}.png\"\n",
    "\n",
    "        # Rename the file\n",
    "        os.rename(file_path, os.path.join(folder_path, new_name))\n",
    "        print(f\"Renamed: {file_name} to {new_name}\")\n",
    "\n",
    "# Replace 'path/to/your/folder' with the actual path to your folder\n",
    "folder_path = 'train_set/CT'\n",
    "rename_files(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN\n",
    "model = YOLO('yolov8n.yaml',task='detect')\n",
    "\n",
    "# Train the model for 10 epochs using the specified data\n",
    "results = model.train(data='CS2.yaml',epochs=100)\n",
    "\n",
    "# Validate the model on a validation set if you have one\n",
    "validation_results = model.val()\n",
    "# Export the trained model to ONNX format\n",
    "success = model.export(format='onnx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462fdace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code will open another window showing the captured screen, video will bw saved as output.avi\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import pyautogui\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(r\"G:\\STEM\\projects\\yolo v8\\runs\\detect\\train25\\weights\\best.pt\")\n",
    "\n",
    "# Create a video writer to save the annotated frames as a video\n",
    "output_video_path = 'output_video.avi'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "# Define the size of the area to capture (1024x1024)\n",
    "capture_width, capture_height = 512,512\n",
    "\n",
    "# Get the screen dimensions\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# Create a VideoWriter with the size of the captured area\n",
    "output_video = cv2.VideoWriter(output_video_path, fourcc, 30.0, (capture_width, capture_height))\n",
    "\n",
    "while True:\n",
    "    # Capture the screen content\n",
    "    screenshot = pyautogui.screenshot()\n",
    "    frame = cv2.cvtColor(np.array(screenshot), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Resize the frame to the desired dimensions\n",
    "    resized_frame = cv2.resize(frame, (capture_width, capture_height))\n",
    "\n",
    "    # Run YOLOv8 inference on the resized frame\n",
    "    results = model(resized_frame)\n",
    "\n",
    "    # Visualize the results on the frame\n",
    "    annotated_frame = results[0].plot()\n",
    "\n",
    "    # Save the annotated frame to the video file\n",
    "    output_video.write(annotated_frame)\n",
    "\n",
    "    # Display the annotated frame if needed (optional)\n",
    "    cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a692ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code will start the auto detection and the mouse movement\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import pyautogui\n",
    "import time\n",
    "import win32api, win32con\n",
    "import pydirectinput\n",
    "import keyboard  # Import the keyboard library\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(r\"G:\\STEM\\projects\\yolo v8\\runs\\detect\\train25\\weights\\best.pt\")\n",
    "\n",
    "# Create a video writer to save the annotated frames as a video\n",
    "output_video_path = 'output_video.avi'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "\n",
    "capture_width, capture_height = 512, 512\n",
    "\n",
    "# Get the screen dimensions\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# Create a VideoWriter with the size of the captured area\n",
    "output_video = cv2.VideoWriter(output_video_path, fourcc, 30.0, (capture_width, capture_height))\n",
    "rate = 1.14\n",
    "\n",
    "\n",
    "\n",
    "def mouse_click(x, y):\n",
    "\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, x, y, 0, 0)\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, x, y, 0, 0)\n",
    "\n",
    "while True:\n",
    "    # Check for the Control + F3 shortcut to stop the loop\n",
    "    if keyboard.is_pressed('ctrl') and keyboard.is_pressed('f3'):\n",
    "        time.sleep(10)\n",
    "    if keyboard.is_pressed('ctrl') and keyboard.is_pressed('f1'):\n",
    "        break\n",
    "\n",
    "    screenshot = pyautogui.screenshot()\n",
    "    frame = cv2.cvtColor(np.array(screenshot), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Resize the frame to the desired dimensions\n",
    "    frame = cv2.resize(frame, (capture_width, capture_height))\n",
    "\n",
    "    # Run YOLOv8 inference on the resized frame\n",
    "    results = model(frame, conf=0.2)\n",
    "    \n",
    "    try:\n",
    "        boxes = results[0].boxes\n",
    "        result = boxes.xyxy[0]\n",
    "\n",
    "        x = ((((((result[2]-result[0])/2)+result[0])-capture_width/2)/capture_width)*2560)*rate\n",
    "        y = ((((((result[3]-result[1])/8.25)+result[1])-capture_height/2)/capture_height)*1600)*rate\n",
    "\n",
    "        # Move the mouse to the target coordinates\n",
    "        # pydirectinput.moveTo(int(x), int(y))\n",
    "        win32api.mouse_event(win32con.MOUSEEVENTF_MOVE, int(x), int(y), 0, 0)\n",
    "        \n",
    "        if (capture_width/2-20)<=((result[2]-result[0])+result[0])<=(capture_width/2+20):\n",
    "            win32api.keybd_event(win32con.VK_CONTROL, 0, win32con.KEYEVENTF_KEYUP, 0)\n",
    "            mouse_click(1260, 800)\n",
    "            time.sleep(0.02)\n",
    "        else:\n",
    "            pass\n",
    "        #mouse_click(1260, 800)\n",
    "        time.sleep(0.05)    \n",
    "        # Optional: Add a delay (in seconds) to observe the movement\n",
    "        \n",
    "    except IndexError:\n",
    "        print(\"No detection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75b28b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the same  code as above but this will log the video\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import pyautogui\n",
    "import time\n",
    "import win32api, win32con\n",
    "import pydirectinput\n",
    "import keyboard  # Import the keyboard library\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(r\"G:\\STEM\\projects\\yolo v8\\runs\\detect\\train25\\weights\\best.pt\")\n",
    "\n",
    "# Create a video writer to save the annotated frames as a video\n",
    "output_video_path = 'output_video.avi'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "\n",
    "capture_width, capture_height = 512, 512\n",
    "\n",
    "# Get the screen dimensions\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# Create a VideoWriter with the size of the captured area\n",
    "output_video = cv2.VideoWriter(output_video_path, fourcc, 30.0, (capture_width, capture_height))\n",
    "rate = 1.21\n",
    "\n",
    "\n",
    "def mouse_click(x, y):\n",
    "\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, x, y, 0, 0)\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, x, y, 0, 0)\n",
    "\n",
    "while True:\n",
    "    # Check for the Control + F3 shortcut to stop the loop\n",
    "    if keyboard.is_pressed('ctrl') and keyboard.is_pressed('f3'):\n",
    "        time.sleep(10)\n",
    "    if keyboard.is_pressed('ctrl') and keyboard.is_pressed('f1'):\n",
    "        break\n",
    "\n",
    "\n",
    "    screenshot = pyautogui.screenshot()\n",
    "    frame = cv2.cvtColor(np.array(screenshot), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Resize the frame to the desired dimensions\n",
    "    frame = cv2.resize(frame, (capture_width, capture_height))\n",
    "\n",
    "    # Run YOLOv8 inference on the resized frame\n",
    "    results = model(frame, conf=0.2, name='T')\n",
    "\n",
    "    \n",
    "    try:\n",
    "        time.sleep(0.15)\n",
    "        boxes = results[0].boxes\n",
    "        result = boxes.xyxy[0]\n",
    "\n",
    "        x = -(1280-(((result[0]+result[2])/2)/capture_width)*2560)*rate\n",
    "        y = ((((((result[3]-result[1])/9)+result[1])-capture_height/2)/capture_height)*1600)*rate\n",
    "\n",
    "        #if (capture_width/2-35)<=((result[2]-result[0])+result[0])<=(capture_width/2+35):\n",
    "            #mouse_click(1260, 800)\n",
    "        #else:\n",
    "            #pass\n",
    "        win32api.mouse_event(win32con.MOUSEEVENTF_MOVE, int(x), int(y), 0, 0)\n",
    "        \n",
    "        mouse_click(1260, 800)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Save the annotated frame to the video file\n",
    "        output_video.write(annotated_frame)\n",
    "\n",
    "        # Optional: Add a delay (in seconds) to observe the movement\n",
    "        \n",
    "    except IndexError:\n",
    "        print(\"No detection\")\n",
    "output_video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f2bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the same  code as above but this will log the video\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import pyautogui\n",
    "import time\n",
    "import win32api, win32con\n",
    "import pydirectinput\n",
    "import keyboard  # Import the keyboard library\n",
    "import math\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(r\"G:\\STEM\\projects\\yolo v8\\runs\\detect\\train25\\weights\\best.pt\")\n",
    "\n",
    "# Create a video writer to save the annotated frames as a video\n",
    "output_video_path = 'output_video.avi'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "\n",
    "capture_width, capture_height = 512, 512\n",
    "\n",
    "# Get the screen dimensions\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# Create a VideoWriter with the size of the captured area\n",
    "output_video = cv2.VideoWriter(output_video_path, fourcc, 30.0, (capture_width, capture_height))\n",
    "rate = 1.21\n",
    "k = 10\n",
    "\n",
    "def mouse_click(x, y):\n",
    "\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, x, y, 0, 0)\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, x, y, 0, 0)\n",
    "\n",
    "while True:\n",
    "    # Check for the Control + F3 shortcut to stop the loop\n",
    "    if keyboard.is_pressed('ctrl') and keyboard.is_pressed('f3'):\n",
    "        time.sleep(10)\n",
    "    if keyboard.is_pressed('ctrl') and keyboard.is_pressed('f1'):\n",
    "        break\n",
    "\n",
    "\n",
    "    screenshot = pyautogui.screenshot()\n",
    "    frame = cv2.cvtColor(np.array(screenshot), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Resize the frame to the desired dimensions\n",
    "    frame = cv2.resize(frame, (capture_width, capture_height))\n",
    "\n",
    "    # Run YOLOv8 inference on the resized frame\n",
    "    results = model(frame, conf=0.2, name='T')\n",
    "\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        if (capture_width/2-15)<=((result[2]-result[0])+result[0])<=(capture_width/2+15):\n",
    "            mouse_click(1260, 800)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Save the annotated frame to the video file\n",
    "        output_video.write(annotated_frame)\n",
    "\n",
    "        # Optional: Add a delay (in seconds) to observe the movement\n",
    "        \n",
    "    except IndexError:\n",
    "        print(\"No detection\")\n",
    "output_video.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
